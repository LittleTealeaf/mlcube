{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "[Reinforcement Learning Article](https://towardsdatascience.com/reinforcement-learning-explained-visually-part-5-deep-q-networks-step-by-step-5a5317197f4b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from random import Random\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move Methods\n",
    "\n",
    "So I did some syntax lessons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Move:\n",
    "    def __init__(\n",
    "        self, name: str, loops: list[list[int]], two: bool = False, prime: bool = False\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.matrix: np.ndarray = np.identity(9 * 6, dtype=np.int8)\n",
    "        for loop in loops:\n",
    "            first = np.copy(self.matrix[loop[0]])\n",
    "            for i in range(len(loop) - 1):\n",
    "                self.matrix[loop[i]] = self.matrix[loop[i + 1]]\n",
    "            self.matrix[loop[-1]] = first\n",
    "        if two:\n",
    "            self.matrix = self.matrix @ self.matrix\n",
    "        if prime:\n",
    "            self.matrix = self.matrix.T\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Move: {self.name}\"\n",
    "\n",
    "\n",
    "def build_moves(letter: str, loops: list[list[int]]) -> list[Move]:\n",
    "    return [\n",
    "        Move(letter, loops),\n",
    "        Move(f\"{letter}P\", loops, prime=True),\n",
    "        Move(f\"{letter}2\", loops, two=True),\n",
    "    ]\n",
    "\n",
    "\n",
    "# Behold, python syntax\n",
    "MOVES = [\n",
    "    move\n",
    "    for moves in [\n",
    "        build_moves(\n",
    "            \"R\",\n",
    "            [\n",
    "                [20, 2, 42, 47],\n",
    "                [23, 5, 39, 50],\n",
    "                [26, 8, 36, 53],\n",
    "                [27, 29, 35, 33],\n",
    "                [28, 32, 34, 30],\n",
    "            ],\n",
    "        ),\n",
    "        build_moves(\n",
    "            \"U\",\n",
    "            [\n",
    "                [20, 11, 38, 29],\n",
    "                [19, 10, 37, 28],\n",
    "                [18, 9, 36, 27],\n",
    "                [8, 6, 0, 2],\n",
    "                [7, 3, 1, 5],\n",
    "            ],\n",
    "        ),\n",
    "        build_moves(\n",
    "            \"L\",\n",
    "            [\n",
    "                [18, 45, 44, 0],\n",
    "                [21, 48, 41, 3],\n",
    "                [24, 51, 38, 6],\n",
    "                [11, 17, 15, 9],\n",
    "                [14, 16, 12, 10],\n",
    "            ],\n",
    "        ),\n",
    "        build_moves(\n",
    "            \"D\",\n",
    "            [\n",
    "                [24, 33, 42, 15],\n",
    "                [25, 34, 43, 16],\n",
    "                [26, 35, 44, 17],\n",
    "                [45, 47, 53, 51],\n",
    "                [46, 50, 52, 48],\n",
    "            ],\n",
    "        ),\n",
    "        build_moves(\n",
    "            \"F\",\n",
    "            [\n",
    "                [6, 27, 47, 17],\n",
    "                [7, 30, 46, 14],\n",
    "                [8, 33, 45, 11],\n",
    "                [18, 20, 26, 24],\n",
    "                [19, 23, 25, 21],\n",
    "            ],\n",
    "        ),\n",
    "        build_moves(\n",
    "            \"B\",\n",
    "            [\n",
    "                [36, 38, 44, 42],\n",
    "                [37, 41, 43, 39],\n",
    "                [29, 0, 15, 53],\n",
    "                [32, 1, 12, 52],\n",
    "                [35, 2, 9, 51],\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "    for move in moves\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Cube Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_cube():\n",
    "    state = np.zeros((9 * 6), dtype=np.int8)\n",
    "    for i in range(state.size):\n",
    "        state[i] = i / 9\n",
    "    return state\n",
    "\n",
    "\n",
    "def apply_move(state, move: Move) -> np.ndarray:\n",
    "    return state @ move.matrix\n",
    "\n",
    "\n",
    "def scramble(state: np.ndarray, count: int) -> np.ndarray:\n",
    "    random = Random()\n",
    "    return state @ reduce(\n",
    "        lambda a, b: a @ b, [random.choice(MOVES).matrix for i in range(count)]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The chance that the agent will choose to explore instead of picking the best answer'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPSILON = 0.5\n",
    "\"The chance that the agent will choose to explore instead of picking the best answer\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting State to Vector\n",
    "\n",
    "In order to make an accurate network, we will need to convert the cube's state array to a longer array to make it clearer to the network what color is where\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_vector(state):\n",
    "    vector = np.zeros((9 * 6 * 6,1),dtype=np.float32)\n",
    "    for i in range(9 * 6):\n",
    "        color = state[i]\n",
    "        vector[i * 6 + color] = 1\n",
    "    return vector.T\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_network(sizes: list[int]) -> list[tuple[(tf.Variable, tf.Variable)]]:\n",
    "    sizes = sizes + [len(MOVES)]\n",
    "    values = []\n",
    "    for i in range(len(sizes)):\n",
    "        size = sizes[i]\n",
    "        prev_size = 9 * 6 * 6\n",
    "        if i > 0:\n",
    "            prev_size = sizes[i - 1]\n",
    "        weights = tf.Variable(\n",
    "            tf.random.normal([prev_size, size], stddev=0.03), name=f\"W{i+1}\"\n",
    "        )\n",
    "        constants = tf.Variable(tf.random.normal([size]), name=f\"b{i+1}\")\n",
    "        values.append((weights, constants))\n",
    "    return values\n",
    "\n",
    "\n",
    "def feed_network(state, network: list[tuple[(tf.Variable, tf.Variable)]]):\n",
    "    x = tf.cast(state, tf.float32)\n",
    "    for i in range(len(network)):\n",
    "        W, b = network[i]\n",
    "        if i > 0:\n",
    "            x = tf.nn.relu(x)\n",
    "        x = tf.add(tf.matmul(x, W), b)\n",
    "    return x\n",
    "\n",
    "\n",
    "def copy_network(network: list[tuple[(tf.Variable, tf.Variable)]]):\n",
    "    copy = []\n",
    "    for layer in network:\n",
    "        W, b = layer\n",
    "        copy.append((np.copy(W), np.copy(b)))\n",
    "    return copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(state: np.ndarray):\n",
    "    value = 0\n",
    "    for i in range(9 * 6):\n",
    "        if state[i] == i // 9:\n",
    "            value = value + 1\n",
    "        else:\n",
    "            value = value - 1\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_replay(\n",
    "    network: list[tuple[(tf.Variable, tf.Variable)]],\n",
    "    count: int,\n",
    "    epsilon: float = EPSILON,\n",
    "):\n",
    "    replays: list[\n",
    "        tuple[\n",
    "            (\n",
    "                np.ndarray,  # current state\n",
    "                int,  # action\n",
    "                np.ndarray,  # next state\n",
    "                tf.float32,  # Q-Value\n",
    "            )\n",
    "        ]\n",
    "    ] = []\n",
    "\n",
    "    random = Random()\n",
    "\n",
    "    cube = scramble(new_cube(), 10000)\n",
    "\n",
    "    for i in range(count):\n",
    "        choice: int = -1\n",
    "        if random.random() < epsilon:\n",
    "            choice = random.randrange(0, len(MOVES))\n",
    "        else:\n",
    "            q_vals = feed_network(state_to_vector(cube), network)\n",
    "            index_max = tf.argmax(q_vals, 1).numpy()[0]\n",
    "            choice = index_max\n",
    "        new_state = apply_move(cube, MOVES[choice])\n",
    "\n",
    "        replays.append(\n",
    "            (\n",
    "                state_to_vector(cube),\n",
    "                choice,\n",
    "                state_to_vector(new_state),\n",
    "                get_reward(new_state),\n",
    "            )\n",
    "        )\n",
    "        cube = new_state\n",
    "\n",
    "    return replays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Predictor\n",
    "\n",
    "This function tests how well the network runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(network):\n",
    "    total_value = 0\n",
    "    for i in range(32):\n",
    "        cube = scramble(new_cube(), 100)\n",
    "        count = 0\n",
    "        while count < 100 and get_reward(cube) < 9 * 6:\n",
    "            count: int = count + 1\n",
    "            vals = feed_network(state_to_vector(cube), network)\n",
    "            apply_move(cube, MOVES[tf.argmax(vals)[0]])\n",
    "\n",
    "        total_value: int = get_reward(cube)\n",
    "    return total_value / 100.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Operation\n",
    "\n",
    "I think this is what it does\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN(\n",
    "    network: list[tuple[(tf.Variable, tf.Variable)]],\n",
    "    target: list[tuple[(tf.Variable, tf.Variable)]],\n",
    "    replays: list[\n",
    "        tuple[\n",
    "            (\n",
    "                np.ndarray,\n",
    "                int,\n",
    "                np.ndarray,\n",
    "                tf.float32,\n",
    "            )\n",
    "        ]\n",
    "    ],\n",
    "    lr_schedule=tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-2, decay_steps=10000, decay_rate=0.9\n",
    "    ),\n",
    "):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # I HAVE NO IDEA\n",
    "        trainable_variables = [var for vars in network for var in vars]\n",
    "\n",
    "        for variable in trainable_variables:\n",
    "            tape.watch(variable)\n",
    "\n",
    "        action = [replay[1] for replay in replays]\n",
    "        for i in range(len(action)):\n",
    "            tmp = np.zeros((1, len(MOVES)), dtype=np.float32)\n",
    "            tmp[0][action[i]] = 1.0\n",
    "            action[i] = tmp.T\n",
    "\n",
    "        state_1 = tf.constant([replay[0] for replay in replays], dtype=tf.float32)\n",
    "        action = tf.constant(action, dtype=tf.float32)\n",
    "        state_2 = tf.constant([replay[2] for replay in replays], dtype=tf.float32)\n",
    "        reward = tf.constant([replay[3] for replay in replays], dtype=tf.float32)\n",
    "\n",
    "        # Calculates Q values of the first state\n",
    "        state_1_q = feed_network(state_1, network)\n",
    "\n",
    "        # makes a selection matrix for state_1\n",
    "        state_1_max = tf.matmul(state_1_q, action)[:, 0, 0]\n",
    "\n",
    "        # gets the Q value of the selected action\n",
    "        state_2_q = feed_network(state_2, target)\n",
    "\n",
    "        state_2_max = tf.argmax(state_2_q, axis=2)\n",
    "\n",
    "        predicted_q = state_1_max\n",
    "\n",
    "        target_q = tf.add(reward, tf.cast(state_2_max[:, 0], dtype=tf.float32))\n",
    "        loss = tf.square(target_q - predicted_q)\n",
    "\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "        gradients = tape.gradient(loss, trainable_variables)\n",
    "\n",
    "        opt.apply_gradients(zip(gradients, trainable_variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing and Retrieving State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_network(network):\n",
    "    data = [\n",
    "        {\n",
    "            'W': W.numpy().tolist(),\n",
    "            'B': B.numpy().tolist()\n",
    "        }\n",
    "        for (W,B) in network\n",
    "    ]\n",
    "    return data\n",
    "\n",
    "def restore_network(serialized):\n",
    "    return [\n",
    "        (\n",
    "            tf.Variable(A['W']),\n",
    "            tf.Variable(A['B'])\n",
    "        )\n",
    "        for A in serialized\n",
    "    ]\n",
    "\n",
    "def load_json(name):\n",
    "    with open(name) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(name,data):\n",
    "    with open(name,'w') as f:\n",
    "        f.write(json.dumps(data))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OK, LETS SEE...\n",
    "\n",
    "# network = random_network([10, 10])\n",
    "# target = copy_network(network)\n",
    "# Attempts to restore the network from a file\n",
    "\n",
    "network = random_network([10,10])\n",
    "\n",
    "if os.path.exists('./network.json'):\n",
    "    network = restore_network(load_json('./network.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Accuracy: -0.16\n",
      "Batch 1: Accuracy: -0.32\n",
      "Batch 2: Accuracy: -0.3\n",
      "Batch 3: Accuracy: -0.28\n",
      "Batch 4: Accuracy: -0.3\n",
      "Batch 5: Accuracy: -0.26\n",
      "Batch 6: Accuracy: -0.3\n",
      "Batch 7: Accuracy: -0.26\n",
      "Batch 8: Accuracy: -0.22\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\Github\\mlcube\\notebook.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell://tunneling%2Bteatopwindows/f%3A/Github/mlcube/notebook.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m target_update_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell://tunneling%2Bteatopwindows/f%3A/Github/mlcube/notebook.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     target \u001b[39m=\u001b[39m copy_network(network)\n\u001b[1;32m---> <a href='vscode-notebook-cell://tunneling%2Bteatopwindows/f%3A/Github/mlcube/notebook.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m replay \u001b[39m=\u001b[39m create_replay(network, batch_size, epsilon\u001b[39m=\u001b[39;49mi \u001b[39m/\u001b[39;49m batch_count)\n\u001b[0;32m     <a href='vscode-notebook-cell://tunneling%2Bteatopwindows/f%3A/Github/mlcube/notebook.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m replay_sample \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msample(replay, batch_sample_size)\n\u001b[0;32m     <a href='vscode-notebook-cell://tunneling%2Bteatopwindows/f%3A/Github/mlcube/notebook.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m DQN(network, target, replay_sample,lr_schedule\u001b[39m=\u001b[39mlr_schedule)\n",
      "\u001b[1;32mf:\\Github\\mlcube\\notebook.ipynb Cell 27\u001b[0m in \u001b[0;36mcreate_replay\u001b[1;34m(network, count, epsilon)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell://tunneling%2Bteatopwindows/f%3A/Github/mlcube/notebook.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell://tunneling%2Bteatopwindows/f%3A/Github/mlcube/notebook.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     q_vals \u001b[39m=\u001b[39m feed_network(state_to_vector(cube), network)\n\u001b[1;32m---> <a href='vscode-notebook-cell://tunneling%2Bteatopwindows/f%3A/Github/mlcube/notebook.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     index_max \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49margmax(q_vals, \u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mnumpy()[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell://tunneling%2Bteatopwindows/f%3A/Github/mlcube/notebook.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     choice \u001b[39m=\u001b[39m index_max\n\u001b[0;32m     <a href='vscode-notebook-cell://tunneling%2Bteatopwindows/f%3A/Github/mlcube/notebook.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m new_state \u001b[39m=\u001b[39m apply_move(cube, MOVES[choice])\n",
      "File \u001b[1;32mc:\\Users\\Littl\\anaconda3\\envs\\mlcube\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1159\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \n\u001b[0;32m   1138\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1159\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\Littl\\anaconda3\\envs\\mlcube\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1125\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1124\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1125\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   1126\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "batch_sample_size = 1000\n",
    "batch_count = 100\n",
    "target_update_interval = 5\n",
    "\n",
    "random = Random()\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-2, decay_steps=batch_count, decay_rate=0.9\n",
    "    )\n",
    "\n",
    "for i in range(batch_count):\n",
    "    if i % target_update_interval == 0:\n",
    "        target = copy_network(network)\n",
    "    replay = create_replay(network, batch_size, epsilon=i / batch_count)\n",
    "    replay_sample = random.sample(replay, batch_sample_size)\n",
    "    DQN(network, target, replay_sample,lr_schedule=lr_schedule)\n",
    "    value = accuracy(network)\n",
    "    save_json('./network.json',store_network(network))\n",
    "    print(f\"Batch {i}: Accuracy: {value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('mlcube')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7641580b910c9b01375a0fd9701e80f509c3f72b49a4ffa822590e7a07fce613"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
