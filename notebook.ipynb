{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "[Reinforcement Learning Article](https://towardsdatascience.com/reinforcement-learning-explained-visually-part-5-deep-q-networks-step-by-step-5a5317197f4b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from random import Random\n",
    "from functools import reduce\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move Methods\n",
    "\n",
    "So I did some syntax lessons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Move:\n",
    "    def __init__(\n",
    "        self, name: str, loops: list[list[int]], two: bool = False, prime: bool = False\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.matrix: np.ndarray = np.identity(9 * 6, dtype=np.int8)\n",
    "        for loop in loops:\n",
    "            first = np.copy(self.matrix[loop[0]])\n",
    "            for i in range(len(loop) - 1):\n",
    "                self.matrix[loop[i]] = self.matrix[loop[i + 1]]\n",
    "            self.matrix[loop[-1]] = first\n",
    "        if two:\n",
    "            self.matrix = self.matrix @ self.matrix\n",
    "        if prime:\n",
    "            self.matrix = self.matrix.T\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Move: {self.name}\"\n",
    "\n",
    "\n",
    "def build_moves(letter: str, loops: list[list[int]]) -> list[Move]:\n",
    "    return [\n",
    "        Move(letter, loops),\n",
    "        Move(f\"{letter}P\", loops, prime=True),\n",
    "        Move(f\"{letter}2\", loops, two=True),\n",
    "    ]\n",
    "\n",
    "\n",
    "# Behold, python syntax\n",
    "MOVES = [\n",
    "    move\n",
    "    for moves in [\n",
    "        build_moves(\n",
    "            \"R\",\n",
    "            [\n",
    "                [20, 2, 42, 47],\n",
    "                [23, 5, 39, 50],\n",
    "                [26, 8, 36, 53],\n",
    "                [27, 29, 35, 33],\n",
    "                [28, 32, 34, 30],\n",
    "            ],\n",
    "        ),\n",
    "        build_moves(\n",
    "            \"U\",\n",
    "            [\n",
    "                [20, 11, 38, 29],\n",
    "                [19, 10, 37, 28],\n",
    "                [18, 9, 36, 27],\n",
    "                [8, 6, 0, 2],\n",
    "                [7, 3, 1, 5],\n",
    "            ],\n",
    "        ),\n",
    "        build_moves(\n",
    "            \"L\",\n",
    "            [\n",
    "                [18, 45, 44, 0],\n",
    "                [21, 48, 41, 3],\n",
    "                [24, 51, 38, 6],\n",
    "                [11, 17, 15, 9],\n",
    "                [14, 16, 12, 10],\n",
    "            ],\n",
    "        ),\n",
    "        build_moves(\n",
    "            \"D\",\n",
    "            [\n",
    "                [24, 33, 42, 15],\n",
    "                [25, 34, 43, 16],\n",
    "                [26, 35, 44, 17],\n",
    "                [45, 47, 53, 51],\n",
    "                [46, 50, 52, 48],\n",
    "            ],\n",
    "        ),\n",
    "        build_moves(\n",
    "            \"F\",\n",
    "            [\n",
    "                [6, 27, 47, 17],\n",
    "                [7, 30, 46, 14],\n",
    "                [8, 33, 45, 11],\n",
    "                [18, 20, 26, 24],\n",
    "                [19, 23, 25, 21],\n",
    "            ],\n",
    "        ),\n",
    "        build_moves(\n",
    "            \"B\",\n",
    "            [\n",
    "                [36, 38, 44, 42],\n",
    "                [37, 41, 43, 39],\n",
    "                [29, 0, 15, 53],\n",
    "                [32, 1, 12, 52],\n",
    "                [35, 2, 9, 51],\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "    for move in moves\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Cube Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_cube():\n",
    "    state = np.zeros((9 * 6), dtype=np.int8)\n",
    "    for i in range(state.size):\n",
    "        state[i] = i / 9\n",
    "    return state\n",
    "\n",
    "\n",
    "def apply_move(state, move: Move) -> np.ndarray:\n",
    "    return state @ move.matrix\n",
    "\n",
    "\n",
    "def scramble(state: np.ndarray, count: int) -> np.ndarray:\n",
    "    random = Random()\n",
    "    return state @ reduce(\n",
    "        lambda a, b: a @ b, [random.choice(MOVES).matrix for i in range(count)]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The chance that the agent will choose to explore instead of picking the best answer'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPSILON = 0.5\n",
    "\"The chance that the agent will choose to explore instead of picking the best answer\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting State to Vector\n",
    "\n",
    "In order to make an accurate network, we will need to convert the cube's state array to a longer array to make it clearer to the network what color is where\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_vector(state):\n",
    "    vector = np.zeros((9 * 6 * 6,1),dtype=np.float32)\n",
    "    for i in range(9 * 6):\n",
    "        color = state[i]\n",
    "        vector[i * 6 + color] = 1\n",
    "    return vector.T\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_network(sizes: list[int]) -> list[tuple[(tf.Variable, tf.Variable)]]:\n",
    "    sizes = sizes + [len(MOVES)]\n",
    "    values = []\n",
    "    for i in range(len(sizes)):\n",
    "        size = sizes[i]\n",
    "        prev_size = 9 * 6 * 6\n",
    "        if i > 0:\n",
    "            prev_size = sizes[i - 1]\n",
    "        weights = tf.Variable(\n",
    "            tf.random.normal([prev_size, size], stddev=0.03), name=f\"W{i+1}\"\n",
    "        )\n",
    "        constants = tf.Variable(tf.random.normal([size]), name=f\"b{i+1}\")\n",
    "        values.append((weights, constants))\n",
    "    return values\n",
    "\n",
    "\n",
    "def feed_network(state, network: list[tuple[(tf.Variable, tf.Variable)]]):\n",
    "    x = tf.cast(state, tf.float32)\n",
    "    for i in range(len(network)):\n",
    "        W, b = network[i]\n",
    "        if i > 0:\n",
    "            x = tf.nn.relu(x)\n",
    "        x = tf.add(tf.matmul(x, W), b)\n",
    "    return x\n",
    "\n",
    "\n",
    "def copy_network(network: list[tuple[(tf.Variable, tf.Variable)]]):\n",
    "    copy = []\n",
    "    for layer in network:\n",
    "        W, b = layer\n",
    "        copy.append((np.copy(W), np.copy(b)))\n",
    "    return copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(state: np.ndarray):\n",
    "    value = 0\n",
    "    for i in range(9 * 6):\n",
    "        if state[i] == i // 9:\n",
    "            value = value + 1\n",
    "        else:\n",
    "            value = value - 1\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_replay(\n",
    "    network: list[tuple[(tf.Variable, tf.Variable)]],\n",
    "    count: int,\n",
    "    epsilon: float = EPSILON,\n",
    "):\n",
    "    replays: list[\n",
    "        tuple[\n",
    "            (\n",
    "                np.ndarray,  # current state\n",
    "                int,  # action\n",
    "                np.ndarray,  # next state\n",
    "                tf.float32,  # Q-Value\n",
    "            )\n",
    "        ]\n",
    "    ] = []\n",
    "\n",
    "    random = Random()\n",
    "\n",
    "    cube = scramble(new_cube(), 10000)\n",
    "\n",
    "    for i in range(count):\n",
    "        choice: int = -1\n",
    "        if random.random() < epsilon:\n",
    "            choice = random.randrange(0,len(MOVES))\n",
    "        else:\n",
    "            q_vals = feed_network(state_to_vector(cube), network)\n",
    "            index_max = tf.argmax(q_vals, 1).numpy()[0]\n",
    "            choice = index_max\n",
    "        new_state = apply_move(cube, MOVES[choice])\n",
    "\n",
    "        replays.append((state_to_vector(cube), choice, state_to_vector(new_state), get_reward(new_state)))\n",
    "        cube = new_state\n",
    "\n",
    "    return replays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Predictor\n",
    "This function tests how well the network runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(network):\n",
    "    total_value = 0\n",
    "    for i in range(100):\n",
    "        cube = scramble(new_cube(),100)\n",
    "        count = 0\n",
    "        while count < 100 and get_reward(cube) < 9 * 6:\n",
    "            count: int = count + 1\n",
    "            vals = feed_network(state_to_vector(cube),network)\n",
    "            apply_move(cube,MOVES[tf.argmax(vals)[0]])\n",
    "\n",
    "        total_value: int = get_reward(cube)\n",
    "    return total_value / 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Operation\n",
    "\n",
    "I think this is what it does\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN(\n",
    "    network: list[tuple[(tf.Variable, tf.Variable)]],\n",
    "    target: list[tuple[(tf.Variable, tf.Variable)]],\n",
    "    replays: list[\n",
    "        tuple[\n",
    "            (\n",
    "                np.ndarray,\n",
    "                int,\n",
    "                np.ndarray,\n",
    "                tf.float32,\n",
    "            )\n",
    "        ]\n",
    "    ],\n",
    "):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "\n",
    "        # I HAVE NO IDEA\n",
    "        trainable_variables = [var for vars in network for var in vars]\n",
    "\n",
    "        for variable in trainable_variables:\n",
    "            tape.watch(variable)\n",
    "\n",
    "        action = [replay[1] for replay in replays]\n",
    "        for i in range(len(action)):\n",
    "            tmp = np.zeros((1,len(MOVES)),dtype=np.float32)\n",
    "            tmp[0][action[i]] = 1.0\n",
    "            action[i] = tmp.T\n",
    "\n",
    "\n",
    "        state_1 = tf.constant([replay[0] for replay in replays],dtype=tf.float32)\n",
    "        action = tf.constant(action,dtype=tf.float32)\n",
    "        state_2 = tf.constant([replay[2] for replay in replays],dtype=tf.float32)\n",
    "        reward = tf.constant([replay[3] for replay in replays],dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Calculates Q values of the first state\n",
    "        state_1_q = feed_network(state_1,network)\n",
    "\n",
    "        # makes a selection matrix for state_1\n",
    "        state_1_max = tf.matmul(state_1_q,action)[:,0,0]\n",
    "\n",
    "        # gets the Q value of the selected action\n",
    "        state_2_q = feed_network(state_2,target)\n",
    "\n",
    "        state_2_max = tf.argmax(state_2_q,axis=2)\n",
    "\n",
    "        predicted_q = state_1_max\n",
    "\n",
    "\n",
    "\n",
    "        target_q = tf.add(reward,tf.cast(state_2_max[:,0],dtype=tf.float32))\n",
    "        loss = tf.square(target_q - predicted_q)\n",
    "\n",
    "\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "        gradients = tape.gradient(loss,trainable_variables)\n",
    "\n",
    "        opt.apply_gradients(zip(gradients,trainable_variables))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK, LETS SEE...\n",
    "\n",
    "batch_size = 1000\n",
    "batch_sample_size = 10\n",
    "batch_count = 100\n",
    "target_update_interval = 5\n",
    "\n",
    "network = random_network([10,10])\n",
    "target = copy_network(network)\n",
    "\n",
    "random = Random()\n",
    "\n",
    "for i in range(batch_count):\n",
    "    if i%target_update_interval == 0:\n",
    "        target = copy_network(network)\n",
    "    replay = create_replay(network,batch_size,epsilon=i / batch_count)\n",
    "    replay_sample = random.sample(replay,batch_sample_size)\n",
    "    DQN(network,target,replay_sample)\n",
    "    value = accuracy(network)\n",
    "    print(f'Batch {i}: Accuracy: {value}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('mlcube')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7641580b910c9b01375a0fd9701e80f509c3f72b49a4ffa822590e7a07fce613"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
