{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "[Reinforcement Learning Article](https://towardsdatascience.com/reinforcement-learning-explained-visually-part-5-deep-q-networks-step-by-step-5a5317197f4b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from random import Random\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move Methods\n",
    "\n",
    "So I did some syntax lessons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Move:\n",
    "    def __init__(\n",
    "        self, name: str, loops: list[list[int]], two: bool = False, prime: bool = False\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.matrix: np.ndarray = np.identity(9 * 6, dtype=np.int8)\n",
    "        for loop in loops:\n",
    "            first = np.copy(self.matrix[loop[0]])\n",
    "            for i in range(len(loop) - 1):\n",
    "                self.matrix[loop[i]] = self.matrix[loop[i + 1]]\n",
    "            self.matrix[loop[-1]] = first\n",
    "        if two:\n",
    "            self.matrix = self.matrix @ self.matrix\n",
    "        if prime:\n",
    "            self.matrix = self.matrix.T\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Move: {self.name}\"\n",
    "\n",
    "\n",
    "def build_moves(letter: str, loops: list[list[int]]) -> list[Move]:\n",
    "    return [\n",
    "        Move(letter, loops),\n",
    "        Move(f\"{letter}P\", loops, prime=True),\n",
    "        Move(f\"{letter}2\", loops, two=True),\n",
    "    ]\n",
    "\n",
    "\n",
    "# Behold, python syntax\n",
    "MOVES = [\n",
    "    move\n",
    "    for moves in [\n",
    "        build_moves(\n",
    "            \"R\",\n",
    "            [\n",
    "                [20, 2, 42, 47],\n",
    "                [23, 5, 39, 50],\n",
    "                [26, 8, 36, 53],\n",
    "                [27, 29, 35, 33],\n",
    "                [28, 32, 34, 30],\n",
    "            ],\n",
    "        ),\n",
    "        build_moves(\n",
    "            \"U\",\n",
    "            [\n",
    "                [20, 11, 38, 29],\n",
    "                [19, 10, 37, 28],\n",
    "                [18, 9, 36, 27],\n",
    "                [8, 6, 0, 2],\n",
    "                [7, 3, 1, 5],\n",
    "            ],\n",
    "        ),\n",
    "        build_moves(\n",
    "            \"L\",\n",
    "            [\n",
    "                [18, 45, 44, 0],\n",
    "                [21, 48, 41, 3],\n",
    "                [24, 51, 38, 6],\n",
    "                [11, 17, 15, 9],\n",
    "                [14, 16, 12, 10],\n",
    "            ],\n",
    "        ),\n",
    "        build_moves(\n",
    "            \"D\",\n",
    "            [\n",
    "                [24, 33, 42, 15],\n",
    "                [25, 34, 43, 16],\n",
    "                [26, 35, 44, 17],\n",
    "                [45, 47, 53, 51],\n",
    "                [46, 50, 52, 48],\n",
    "            ],\n",
    "        ),\n",
    "        build_moves(\n",
    "            \"F\",\n",
    "            [\n",
    "                [6, 27, 47, 17],\n",
    "                [7, 30, 46, 14],\n",
    "                [8, 33, 45, 11],\n",
    "                [18, 20, 26, 24],\n",
    "                [19, 23, 25, 21],\n",
    "            ],\n",
    "        ),\n",
    "        build_moves(\n",
    "            \"B\",\n",
    "            [\n",
    "                [36, 38, 44, 42],\n",
    "                [37, 41, 43, 39],\n",
    "                [29, 0, 15, 53],\n",
    "                [32, 1, 12, 52],\n",
    "                [35, 2, 9, 51],\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "    for move in moves\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Cube Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_cube():\n",
    "    state = np.zeros((9 * 6), dtype=np.int8)\n",
    "    for i in range(state.size):\n",
    "        state[i] = i / 9\n",
    "    return state\n",
    "\n",
    "\n",
    "def apply_move(state, move: Move) -> np.ndarray:\n",
    "    return state @ move.matrix\n",
    "\n",
    "\n",
    "def scramble(state: np.ndarray, count: int) -> np.ndarray:\n",
    "    random = Random()\n",
    "    return state @ reduce(\n",
    "        lambda a, b: a @ b, [random.choice(MOVES).matrix for i in range(count)]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The chance that the agent will choose to explore instead of picking the best answer'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPSILON = 0.5\n",
    "\"The chance that the agent will choose to explore instead of picking the best answer\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting State to Vector\n",
    "\n",
    "In order to make an accurate network, we will need to convert the cube's state array to a longer array to make it clearer to the network what color is where\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_vector(state):\n",
    "    vector = np.zeros((9 * 6 * 6,1),dtype=np.float32)\n",
    "    for i in range(9 * 6):\n",
    "        color = state[i]\n",
    "        vector[i * 6 + color] = 1\n",
    "    return vector.T\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_network(sizes: list[int]) -> list[tuple[(tf.Variable, tf.Variable)]]:\n",
    "    sizes = sizes + [len(MOVES)]\n",
    "    values = []\n",
    "    for i in range(len(sizes)):\n",
    "        size = sizes[i]\n",
    "        prev_size = 9 * 6 * 6\n",
    "        if i > 0:\n",
    "            prev_size = sizes[i - 1]\n",
    "        weights = tf.Variable(\n",
    "            tf.random.normal([prev_size, size], stddev=0.03), name=f\"W{i+1}\"\n",
    "        )\n",
    "        constants = tf.Variable(tf.random.normal([size]), name=f\"b{i+1}\")\n",
    "        values.append((weights, constants))\n",
    "    return values\n",
    "\n",
    "\n",
    "def feed_network(state, network: list[tuple[(tf.Variable, tf.Variable)]]):\n",
    "    x = tf.cast(state, tf.float32)\n",
    "    for i in range(len(network)):\n",
    "        W, b = network[i]\n",
    "        if i > 0:\n",
    "            x = tf.nn.softsign(x)\n",
    "        x = tf.add(tf.matmul(x, W), b)\n",
    "    return x\n",
    "\n",
    "\n",
    "def copy_network(network: list[tuple[(tf.Variable, tf.Variable)]]):\n",
    "    copy = []\n",
    "    for layer in network:\n",
    "        W, b = layer\n",
    "        copy.append((np.copy(W), np.copy(b)))\n",
    "    return copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(state: np.ndarray):\n",
    "    value = 0\n",
    "    for i in range(9 * 6):\n",
    "        if state[i] == i // 9:\n",
    "            value = value + 1\n",
    "        else:\n",
    "            value = value - 1\n",
    "    return value / (9 * 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_replay(\n",
    "    network: list[tuple[(tf.Variable, tf.Variable)]],\n",
    "    count: int,\n",
    "    epsilon: float = EPSILON,\n",
    "):\n",
    "    replays: list[\n",
    "        tuple[\n",
    "            (\n",
    "                np.ndarray,  # current state\n",
    "                int,  # action\n",
    "                np.ndarray,  # next state\n",
    "                tf.float32,  # Q-Value\n",
    "            )\n",
    "        ]\n",
    "    ] = []\n",
    "\n",
    "    random = Random()\n",
    "\n",
    "    cube = scramble(new_cube(), 10000)\n",
    "\n",
    "    for i in range(count):\n",
    "        choice: int = -1\n",
    "        if random.random() < epsilon:\n",
    "            choice = random.randrange(0, len(MOVES))\n",
    "        else:\n",
    "            q_vals = feed_network(state_to_vector(cube), network)\n",
    "            index_max = tf.argmax(q_vals, 1).numpy()[0]\n",
    "            choice = index_max\n",
    "        new_state = apply_move(cube, MOVES[choice])\n",
    "\n",
    "        replays.append(\n",
    "            (\n",
    "                state_to_vector(cube),\n",
    "                choice,\n",
    "                state_to_vector(new_state),\n",
    "                get_reward(new_state),\n",
    "            )\n",
    "        )\n",
    "        cube = new_state\n",
    "\n",
    "    return replays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Predictor\n",
    "\n",
    "This function tests how well the network runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(network):\n",
    "\n",
    "    count = 50\n",
    "    total_value = 0\n",
    "    for i in range(count):\n",
    "        cube = scramble(new_cube(), 100)\n",
    "        count = 0\n",
    "        while count < 100 and get_reward(cube) < 9 * 6:\n",
    "            count: int = count + 1\n",
    "            vals = feed_network(state_to_vector(cube), network)\n",
    "            apply_move(cube, MOVES[tf.argmax(vals)[0]])\n",
    "\n",
    "        total_value: int = total_value + get_reward(cube)\n",
    "    return total_value / count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Operation\n",
    "\n",
    "I think this is what it does\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN(\n",
    "    network: list[tuple[(tf.Variable, tf.Variable)]],\n",
    "    target: list[tuple[(tf.Variable, tf.Variable)]],\n",
    "    replays: list[\n",
    "        tuple[\n",
    "            (\n",
    "                np.ndarray,\n",
    "                int,\n",
    "                np.ndarray,\n",
    "                tf.float32,\n",
    "            )\n",
    "        ]\n",
    "    ],\n",
    "    lr_schedule=tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-2, decay_steps=10000, decay_rate=0.9\n",
    "    ),\n",
    "):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # I HAVE NO IDEA\n",
    "        trainable_variables = [var for vars in network for var in vars]\n",
    "\n",
    "        for variable in trainable_variables:\n",
    "            tape.watch(variable)\n",
    "\n",
    "        action = [replay[1] for replay in replays]\n",
    "        for i in range(len(action)):\n",
    "            tmp = np.zeros((1, len(MOVES)), dtype=np.float32)\n",
    "            tmp[0][action[i]] = 1.0\n",
    "            action[i] = tmp.T\n",
    "\n",
    "        state_1 = tf.constant([replay[0] for replay in replays], dtype=tf.float32)\n",
    "        action = tf.constant(action, dtype=tf.float32)\n",
    "        state_2 = tf.constant([replay[2] for replay in replays], dtype=tf.float32)\n",
    "        reward = tf.constant([replay[3] for replay in replays], dtype=tf.float32)\n",
    "\n",
    "        # Calculates Q values of the first state\n",
    "        state_1_q = feed_network(state_1, network)\n",
    "\n",
    "        # makes a selection matrix for state_1\n",
    "        state_1_max = tf.matmul(state_1_q, action)[:, 0, 0]\n",
    "\n",
    "        # gets the Q value of the selected action\n",
    "        state_2_q = feed_network(state_2, target)\n",
    "\n",
    "        state_2_max = tf.argmax(state_2_q, axis=2)\n",
    "\n",
    "        predicted_q = state_1_max\n",
    "\n",
    "        target_q = tf.add(reward, tf.cast(state_2_max[:, 0], dtype=tf.float32))\n",
    "        loss = tf.square(target_q - predicted_q)\n",
    "\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "        gradients = tape.gradient(loss, trainable_variables)\n",
    "\n",
    "        opt.apply_gradients(zip(gradients, trainable_variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing and Retrieving State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_network(network):\n",
    "    data = [\n",
    "        {\n",
    "            'W': W.numpy().tolist(),\n",
    "            'B': B.numpy().tolist()\n",
    "        }\n",
    "        for (W,B) in network\n",
    "    ]\n",
    "    return data\n",
    "\n",
    "def restore_network(serialized):\n",
    "    return [\n",
    "        (\n",
    "            tf.Variable(A['W']),\n",
    "            tf.Variable(A['B'])\n",
    "        )\n",
    "        for A in serialized\n",
    "    ]\n",
    "\n",
    "def load_json(name):\n",
    "    with open(name) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(name,data):\n",
    "    with open(name,'w') as f:\n",
    "        f.write(json.dumps(data,indent=2))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OK, LETS SEE...\n",
    "\n",
    "# network = random_network([10, 10])\n",
    "# target = copy_network(network)\n",
    "# Attempts to restore the network from a file\n",
    "\n",
    "network = random_network([10,15])\n",
    "\n",
    "if os.path.exists('./network.json'):\n",
    "    network = restore_network(load_json('./network.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Accuracy: -0.24074074074074073, updating learning rate 0.003848593964334705\n",
      "Batch 1: Accuracy: -0.23629629629629625, updating learning rate 0.0038210713305898486\n",
      "Batch 2: Accuracy: -0.238888888888889, updating learning rate 0.003837114197530864\n",
      "Batch 3: Accuracy: -0.2522222222222222, updating learning rate 0.003920151234567901\n",
      "Batch 4: Accuracy: -0.23629629629629637, updating learning rate 0.0038210713305898503\n",
      "Batch 5: Accuracy: -0.2396296296296296, updating learning rate 0.0038417040466392316\n",
      "Batch 6: Accuracy: -0.24888888888888888, updating learning rate 0.0038993086419753086\n",
      "Batch 7: Accuracy: -0.25037037037037035, updating learning rate 0.003908565157750342\n",
      "Batch 8: Accuracy: -0.247037037037037, updating learning rate 0.003887753429355281\n",
      "Batch 9: Accuracy: -0.24666666666666662, updating learning rate 0.003885444444444444\n",
      "Batch 10: Accuracy: -0.23740740740740743, updating learning rate 0.0038279427297668047\n",
      "Batch 11: Accuracy: -0.22555555555555554, updating learning rate 0.003754966049382716\n",
      "Batch 12: Accuracy: -0.23999999999999996, updating learning rate 0.003844\n",
      "Batch 13: Accuracy: -0.23296296296296293, updating learning rate 0.0038004941700960208\n",
      "Batch 14: Accuracy: -0.2348148148148147, updating learning rate 0.0038119190672153635\n",
      "Batch 15: Accuracy: -0.2396296296296297, updating learning rate 0.0038417040466392316\n",
      "Batch 16: Accuracy: -0.22925925925925925, updating learning rate 0.003777695816186557\n",
      "Batch 17: Accuracy: -0.24037037037037037, updating learning rate 0.0038462966392318245\n",
      "Batch 18: Accuracy: -0.2381481481481481, updating learning rate 0.0038325270919067223\n",
      "Batch 19: Accuracy: -0.24296296296296294, updating learning rate 0.0038623923182441707\n",
      "Batch 20: Accuracy: -0.2366666666666666, updating learning rate 0.0038233611111111103\n",
      "Batch 21: Accuracy: -0.24407407407407408, updating learning rate 0.003869300754458162\n",
      "Batch 22: Accuracy: -0.23851851851851832, updating learning rate 0.003834820301783264\n",
      "Batch 23: Accuracy: -0.2381481481481482, updating learning rate 0.0038325270919067223\n",
      "Batch 24: Accuracy: -0.23629629629629625, updating learning rate 0.0038210713305898486\n",
      "Batch 25: Accuracy: -0.23444444444444443, updating learning rate 0.0038096327160493824\n",
      "Batch 26: Accuracy: -0.24370370370370367, updating learning rate 0.0038669972565157753\n",
      "Batch 27: Accuracy: -0.24296296296296296, updating learning rate 0.0038623923182441707\n",
      "Batch 28: Accuracy: -0.25629629629629624, updating learning rate 0.0039457009602194785\n",
      "Batch 29: Accuracy: -0.24370370370370367, updating learning rate 0.0038669972565157753\n",
      "Batch 30: Accuracy: -0.22481481481481475, updating learning rate 0.0037504283264746226\n",
      "Batch 31: Accuracy: -0.22962962962962957, updating learning rate 0.0037799725651577504\n",
      "Batch 32: Accuracy: -0.2533333333333333, updating learning rate 0.003927111111111112\n",
      "Batch 33: Accuracy: -0.24074074074074076, updating learning rate 0.003848593964334705\n",
      "Batch 34: Accuracy: -0.24740740740740744, updating learning rate 0.003890063100137175\n",
      "Batch 35: Accuracy: -0.23592592592592596, updating learning rate 0.003818782235939643\n",
      "Batch 36: Accuracy: -0.24481481481481476, updating learning rate 0.003873909807956104\n",
      "Batch 37: Accuracy: -0.2522222222222221, updating learning rate 0.003920151234567901\n",
      "Batch 38: Accuracy: -0.23296296296296293, updating learning rate 0.0038004941700960208\n",
      "Batch 39: Accuracy: -0.2414814814814815, updating learning rate 0.0038531906721536347\n",
      "Batch 40: Accuracy: -0.2562962962962963, updating learning rate 0.0039457009602194785\n",
      "Batch 41: Accuracy: -0.24592592592592588, updating learning rate 0.003880828532235939\n",
      "Batch 42: Accuracy: -0.24037037037037032, updating learning rate 0.0038462966392318245\n",
      "Batch 43: Accuracy: -0.23740740740740743, updating learning rate 0.0038279427297668047\n",
      "Batch 44: Accuracy: -0.21888888888888888, updating learning rate 0.003714225308641975\n",
      "Batch 45: Accuracy: -0.24777777777777782, updating learning rate 0.003892373456790124\n",
      "Batch 46: Accuracy: -0.26185185185185184, updating learning rate 0.00398067524005487\n",
      "Batch 47: Accuracy: -0.247037037037037, updating learning rate 0.003887753429355281\n",
      "Batch 48: Accuracy: -0.2507407407407407, updating learning rate 0.003910881001371742\n",
      "Batch 49: Accuracy: -0.2433333333333333, updating learning rate 0.0038646944444444436\n",
      "Batch 50: Accuracy: -0.24296296296296302, updating learning rate 0.0038623923182441707\n",
      "Batch 51: Accuracy: -0.24074074074074076, updating learning rate 0.003848593964334705\n",
      "Batch 52: Accuracy: -0.24222222222222217, updating learning rate 0.0038577901234567898\n",
      "Batch 53: Accuracy: -0.2303703703703703, updating learning rate 0.0037845281207133058\n",
      "Batch 54: Accuracy: -0.25555555555555554, updating learning rate 0.003941049382716049\n",
      "Batch 55: Accuracy: -0.24222222222222223, updating learning rate 0.0038577901234567906\n",
      "Batch 56: Accuracy: -0.24592592592592588, updating learning rate 0.003880828532235939\n",
      "Batch 57: Accuracy: -0.2433333333333333, updating learning rate 0.0038646944444444436\n",
      "Batch 58: Accuracy: -0.24333333333333326, updating learning rate 0.0038646944444444436\n",
      "Batch 59: Accuracy: -0.24259259259259258, updating learning rate 0.0038600908779149513\n",
      "Batch 60: Accuracy: -0.23888888888888882, updating learning rate 0.003837114197530864\n",
      "Batch 61: Accuracy: -0.23703703703703705, updating learning rate 0.003825651577503429\n",
      "Batch 62: Accuracy: -0.24814814814814817, updating learning rate 0.0038946844993141294\n",
      "Batch 63: Accuracy: -0.24259259259259258, updating learning rate 0.0038600908779149513\n",
      "Batch 64: Accuracy: -0.23111111111111107, updating learning rate 0.003789086419753086\n",
      "Batch 65: Accuracy: -0.2266666666666666, updating learning rate 0.003761777777777777\n",
      "Batch 66: Accuracy: -0.237037037037037, updating learning rate 0.003825651577503429\n",
      "Batch 67: Accuracy: -0.23481481481481473, updating learning rate 0.0038119190672153635\n",
      "Batch 68: Accuracy: -0.23666666666666664, updating learning rate 0.0038233611111111103\n",
      "Batch 69: Accuracy: -0.24703703703703694, updating learning rate 0.003887753429355281\n",
      "Batch 70: Accuracy: -0.25407407407407406, updating learning rate 0.003931754458161866\n",
      "Batch 71: Accuracy: -0.2618518518518519, updating learning rate 0.00398067524005487\n",
      "Batch 72: Accuracy: -0.24185185185185173, updating learning rate 0.003855490054869684\n",
      "Batch 73: Accuracy: -0.23148148148148137, updating learning rate 0.0037913665980795607\n",
      "Batch 74: Accuracy: -0.23851851851851844, updating learning rate 0.003834820301783264\n",
      "Batch 75: Accuracy: -0.2496296296296297, updating learning rate 0.0039039355281207133\n",
      "Batch 76: Accuracy: -0.24666666666666662, updating learning rate 0.003885444444444444\n",
      "Batch 77: Accuracy: -0.2474074074074074, updating learning rate 0.0038900631001371733\n",
      "Batch 78: Accuracy: -0.26222222222222225, updating learning rate 0.003983012345679013\n",
      "Batch 79: Accuracy: -0.23333333333333328, updating learning rate 0.003802777777777778\n",
      "Batch 80: Accuracy: -0.25222222222222224, updating learning rate 0.003920151234567901\n",
      "Batch 81: Accuracy: -0.24444444444444444, updating learning rate 0.0038716049382716052\n",
      "Batch 82: Accuracy: -0.22999999999999993, updating learning rate 0.0037822499999999996\n",
      "Batch 83: Accuracy: -0.24296296296296288, updating learning rate 0.0038623923182441694\n",
      "Batch 84: Accuracy: -0.23407407407407402, updating learning rate 0.0038073470507544584\n",
      "Batch 85: Accuracy: -0.2355555555555555, updating learning rate 0.0038164938271604935\n",
      "Batch 86: Accuracy: -0.23777777777777775, updating learning rate 0.003830234567901234\n",
      "Batch 87: Accuracy: -0.24444444444444438, updating learning rate 0.0038716049382716052\n",
      "Batch 88: Accuracy: -0.25, updating learning rate 0.00390625\n",
      "Batch 89: Accuracy: -0.24592592592592596, updating learning rate 0.003880828532235939\n",
      "Batch 90: Accuracy: -0.23777777777777775, updating learning rate 0.003830234567901234\n",
      "Batch 91: Accuracy: -0.26407407407407407, updating learning rate 0.003994708161865569\n",
      "Batch 92: Accuracy: -0.237037037037037, updating learning rate 0.003825651577503429\n",
      "Batch 93: Accuracy: -0.24259259259259264, updating learning rate 0.003860090877914953\n",
      "Batch 94: Accuracy: -0.2481481481481481, updating learning rate 0.0038946844993141285\n",
      "Batch 95: Accuracy: -0.23851851851851855, updating learning rate 0.003834820301783265\n",
      "Batch 96: Accuracy: -0.2451851851851852, updating learning rate 0.0038762153635116597\n",
      "Batch 97: Accuracy: -0.23925925925925928, updating learning rate 0.00383940877914952\n",
      "Batch 98: Accuracy: -0.23851851851851846, updating learning rate 0.003834820301783264\n",
      "Batch 99: Accuracy: -0.25074074074074065, updating learning rate 0.003910881001371742\n",
      "Batch 100: Accuracy: -0.2411111111111111, updating learning rate 0.003850891975308642\n",
      "Batch 101: Accuracy: -0.24185185185185187, updating learning rate 0.003855490054869684\n",
      "Batch 102: Accuracy: -0.23777777777777778, updating learning rate 0.0038302345679012352\n",
      "Batch 103: Accuracy: -0.23777777777777773, updating learning rate 0.003830234567901234\n",
      "Batch 104: Accuracy: -0.24777777777777776, updating learning rate 0.003892373456790124\n",
      "Batch 105: Accuracy: -0.24037037037037043, updating learning rate 0.0038462966392318245\n",
      "Batch 106: Accuracy: -0.23407407407407413, updating learning rate 0.0038073470507544584\n",
      "Batch 107: Accuracy: -0.2414814814814814, updating learning rate 0.0038531906721536347\n",
      "Batch 108: Accuracy: -0.24444444444444438, updating learning rate 0.0038716049382716052\n",
      "Batch 109: Accuracy: -0.22703703703703698, updating learning rate 0.0037640497256515772\n",
      "Batch 110: Accuracy: -0.23037037037037034, updating learning rate 0.0037845281207133058\n",
      "Batch 111: Accuracy: -0.25, updating learning rate 0.00390625\n",
      "Batch 112: Accuracy: -0.23481481481481484, updating learning rate 0.0038119190672153635\n",
      "Batch 113: Accuracy: -0.247037037037037, updating learning rate 0.003887753429355281\n",
      "Batch 114: Accuracy: -0.2414814814814815, updating learning rate 0.0038531906721536347\n",
      "Batch 115: Accuracy: -0.2392592592592592, updating learning rate 0.00383940877914952\n",
      "Batch 116: Accuracy: -0.2414814814814815, updating learning rate 0.0038531906721536347\n",
      "Batch 117: Accuracy: -0.23851851851851857, updating learning rate 0.003834820301783265\n",
      "Batch 118: Accuracy: -0.25000000000000006, updating learning rate 0.00390625\n",
      "Batch 119: Accuracy: -0.25629629629629624, updating learning rate 0.0039457009602194785\n",
      "Batch 120: Accuracy: -0.23814814814814814, updating learning rate 0.0038325270919067223\n",
      "Batch 121: Accuracy: -0.2514814814814815, updating learning rate 0.003915514746227709\n",
      "Batch 122: Accuracy: -0.2414814814814815, updating learning rate 0.0038531906721536347\n",
      "Batch 123: Accuracy: -0.2362962962962963, updating learning rate 0.0038210713305898486\n",
      "Batch 124: Accuracy: -0.23814814814814816, updating learning rate 0.0038325270919067223\n",
      "Batch 125: Accuracy: -0.24592592592592588, updating learning rate 0.003880828532235939\n",
      "Batch 126: Accuracy: -0.237037037037037, updating learning rate 0.003825651577503429\n",
      "Batch 127: Accuracy: -0.2407407407407407, updating learning rate 0.003848593964334705\n",
      "Batch 128: Accuracy: -0.24222222222222212, updating learning rate 0.0038577901234567898\n",
      "Batch 129: Accuracy: -0.23740740740740737, updating learning rate 0.0038279427297668034\n",
      "Batch 130: Accuracy: -0.2518518518518519, updating learning rate 0.003917832647462278\n",
      "Batch 131: Accuracy: -0.2348148148148147, updating learning rate 0.0038119190672153635\n",
      "Batch 132: Accuracy: -0.24481481481481476, updating learning rate 0.003873909807956104\n",
      "Batch 133: Accuracy: -0.25666666666666665, updating learning rate 0.003948027777777777\n",
      "Batch 134: Accuracy: -0.23629629629629625, updating learning rate 0.0038210713305898486\n",
      "Batch 135: Accuracy: -0.24555555555555553, updating learning rate 0.0038785216049382716\n",
      "Batch 136: Accuracy: -0.24074074074074064, updating learning rate 0.003848593964334705\n",
      "Batch 137: Accuracy: -0.24703703703703705, updating learning rate 0.0038877534293552817\n",
      "Batch 138: Accuracy: -0.24333333333333332, updating learning rate 0.003864694444444445\n",
      "Batch 139: Accuracy: -0.24481481481481482, updating learning rate 0.003873909807956104\n",
      "Batch 140: Accuracy: -0.24592592592592585, updating learning rate 0.003880828532235939\n",
      "Batch 141: Accuracy: -0.2329629629629629, updating learning rate 0.0038004941700960208\n",
      "Batch 142: Accuracy: -0.23592592592592593, updating learning rate 0.003818782235939643\n",
      "Batch 143: Accuracy: -0.24259259259259253, updating learning rate 0.0038600908779149513\n",
      "Batch 144: Accuracy: -0.2414814814814815, updating learning rate 0.0038531906721536347\n",
      "Batch 145: Accuracy: -0.24222222222222223, updating learning rate 0.0038577901234567906\n",
      "Batch 146: Accuracy: -0.24444444444444446, updating learning rate 0.0038716049382716052\n",
      "Batch 147: Accuracy: -0.2422222222222223, updating learning rate 0.0038577901234567906\n",
      "Batch 148: Accuracy: -0.24740740740740744, updating learning rate 0.003890063100137175\n",
      "Batch 149: Accuracy: -0.2477777777777777, updating learning rate 0.0038923734567901224\n",
      "Batch 150: Accuracy: -0.24888888888888894, updating learning rate 0.0038993086419753086\n",
      "Batch 151: Accuracy: -0.2351851851851852, updating learning rate 0.0038142061042524007\n",
      "Batch 152: Accuracy: -0.23222222222222222, updating learning rate 0.0037959290123456783\n",
      "Batch 153: Accuracy: -0.2388888888888889, updating learning rate 0.003837114197530864\n",
      "Batch 154: Accuracy: -0.23296296296296293, updating learning rate 0.0038004941700960208\n",
      "Batch 155: Accuracy: -0.24851851851851858, updating learning rate 0.003896996227709191\n",
      "Batch 156: Accuracy: -0.2577777777777779, updating learning rate 0.003955012345679013\n",
      "Batch 157: Accuracy: -0.2481481481481481, updating learning rate 0.0038946844993141285\n",
      "Batch 158: Accuracy: -0.244074074074074, updating learning rate 0.003869300754458161\n",
      "Batch 159: Accuracy: -0.2303703703703703, updating learning rate 0.0037845281207133058\n",
      "Batch 160: Accuracy: -0.24592592592592588, updating learning rate 0.003880828532235939\n",
      "Batch 161: Accuracy: -0.2396296296296296, updating learning rate 0.0038417040466392316\n",
      "Batch 162: Accuracy: -0.24851851851851842, updating learning rate 0.00389699622770919\n",
      "Batch 163: Accuracy: -0.23851851851851846, updating learning rate 0.003834820301783264\n",
      "Batch 164: Accuracy: -0.25111111111111106, updating learning rate 0.0039131975308641966\n",
      "Batch 165: Accuracy: -0.24703703703703694, updating learning rate 0.003887753429355281\n",
      "Batch 166: Accuracy: -0.24888888888888894, updating learning rate 0.0038993086419753086\n",
      "Batch 167: Accuracy: -0.25222222222222224, updating learning rate 0.003920151234567901\n",
      "Batch 168: Accuracy: -0.23777777777777775, updating learning rate 0.003830234567901234\n",
      "Batch 169: Accuracy: -0.24148148148148146, updating learning rate 0.0038531906721536347\n",
      "Batch 170: Accuracy: -0.23296296296296298, updating learning rate 0.0038004941700960225\n",
      "Batch 171: Accuracy: -0.24888888888888883, updating learning rate 0.0038993086419753078\n",
      "Batch 172: Accuracy: -0.234074074074074, updating learning rate 0.0038073470507544584\n",
      "Batch 173: Accuracy: -0.2503703703703703, updating learning rate 0.003908565157750342\n",
      "Batch 174: Accuracy: -0.24629629629629618, updating learning rate 0.0038831361454046637\n",
      "Batch 175: Accuracy: -0.25111111111111106, updating learning rate 0.0039131975308641966\n",
      "Batch 176: Accuracy: -0.23185185185185186, updating learning rate 0.0037936474622770927\n",
      "Batch 177: Accuracy: -0.24370370370370367, updating learning rate 0.0038669972565157753\n",
      "Batch 178: Accuracy: -0.23703703703703696, updating learning rate 0.003825651577503429\n",
      "Batch 179: Accuracy: -0.23407407407407407, updating learning rate 0.0038073470507544584\n",
      "Batch 180: Accuracy: -0.24407407407407417, updating learning rate 0.003869300754458162\n",
      "Batch 181: Accuracy: -0.2351851851851851, updating learning rate 0.0038142061042524007\n",
      "Batch 182: Accuracy: -0.24851851851851858, updating learning rate 0.003896996227709191\n",
      "Batch 183: Accuracy: -0.23592592592592596, updating learning rate 0.003818782235939643\n",
      "Batch 184: Accuracy: -0.2548148148148148, updating learning rate 0.003936400548696845\n",
      "Batch 185: Accuracy: -0.24185185185185187, updating learning rate 0.003855490054869684\n",
      "Batch 186: Accuracy: -0.24444444444444438, updating learning rate 0.0038716049382716052\n",
      "Batch 187: Accuracy: -0.2440740740740741, updating learning rate 0.003869300754458162\n",
      "Batch 188: Accuracy: -0.2548148148148148, updating learning rate 0.003936400548696845\n",
      "Batch 189: Accuracy: -0.23037037037037034, updating learning rate 0.0037845281207133058\n",
      "Batch 190: Accuracy: -0.24037037037037026, updating learning rate 0.0038462966392318245\n",
      "Batch 191: Accuracy: -0.23888888888888882, updating learning rate 0.003837114197530864\n",
      "Batch 192: Accuracy: -0.2355555555555556, updating learning rate 0.0038164938271604935\n",
      "Batch 193: Accuracy: -0.24222222222222214, updating learning rate 0.0038577901234567898\n",
      "Batch 194: Accuracy: -0.24814814814814817, updating learning rate 0.0038946844993141294\n",
      "Batch 195: Accuracy: -0.24185185185185185, updating learning rate 0.003855490054869684\n",
      "Batch 196: Accuracy: -0.24481481481481485, updating learning rate 0.003873909807956104\n",
      "Batch 197: Accuracy: -0.22481481481481488, updating learning rate 0.0037504283264746226\n",
      "Batch 198: Accuracy: -0.2318518518518518, updating learning rate 0.003793647462277091\n",
      "Batch 199: Accuracy: -0.24222222222222226, updating learning rate 0.0038577901234567906\n",
      "Batch 200: Accuracy: -0.23185185185185186, updating learning rate 0.0037936474622770927\n",
      "Batch 201: Accuracy: -0.2311111111111111, updating learning rate 0.003789086419753086\n",
      "Batch 202: Accuracy: -0.23666666666666672, updating learning rate 0.003823361111111112\n",
      "Batch 203: Accuracy: -0.25481481481481477, updating learning rate 0.003936400548696845\n",
      "Batch 204: Accuracy: -0.2418518518518519, updating learning rate 0.0038554900548696852\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\Github\\mlcube\\notebook.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Github/mlcube/notebook.ipynb#X35sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m replay_sample \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msample(replay, batch_sample_size)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Github/mlcube/notebook.ipynb#X35sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m DQN(network, target, replay_sample,lr_schedule\u001b[39m=\u001b[39mlearning_rate)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Github/mlcube/notebook.ipynb#X35sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m value \u001b[39m=\u001b[39m accuracy(network)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Github/mlcube/notebook.ipynb#X35sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# Update learning rate\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Github/mlcube/notebook.ipynb#X35sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m learning_rate \u001b[39m=\u001b[39m ((\u001b[39m-\u001b[39m\u001b[39m1.0\u001b[39m \u001b[39m*\u001b[39m (value \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m) \u001b[39m/\u001b[39m \u001b[39m100\u001b[39m\n",
      "\u001b[1;32mf:\\Github\\mlcube\\notebook.ipynb Cell 27\u001b[0m in \u001b[0;36maccuracy\u001b[1;34m(network)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Github/mlcube/notebook.ipynb#X35sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mwhile\u001b[39;00m count \u001b[39m<\u001b[39m \u001b[39m100\u001b[39m \u001b[39mand\u001b[39;00m get_reward(cube) \u001b[39m<\u001b[39m \u001b[39m9\u001b[39m \u001b[39m*\u001b[39m \u001b[39m6\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Github/mlcube/notebook.ipynb#X35sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     count: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m count \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Github/mlcube/notebook.ipynb#X35sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     vals \u001b[39m=\u001b[39m feed_network(state_to_vector(cube), network)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Github/mlcube/notebook.ipynb#X35sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     apply_move(cube, MOVES[tf\u001b[39m.\u001b[39margmax(vals)[\u001b[39m0\u001b[39m]])\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Github/mlcube/notebook.ipynb#X35sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m total_value: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m total_value \u001b[39m+\u001b[39m get_reward(cube)\n",
      "\u001b[1;32mf:\\Github\\mlcube\\notebook.ipynb Cell 27\u001b[0m in \u001b[0;36mfeed_network\u001b[1;34m(state, network)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Github/mlcube/notebook.ipynb#X35sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Github/mlcube/notebook.ipynb#X35sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         x \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39msoftsign(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Github/mlcube/notebook.ipynb#X35sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     x \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39madd(tf\u001b[39m.\u001b[39;49mmatmul(x, W), b)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Github/mlcube/notebook.ipynb#X35sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Littl\\anaconda3\\envs\\mlcube\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Littl\\anaconda3\\envs\\mlcube\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Littl\\anaconda3\\envs\\mlcube\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3713\u001b[0m, in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[0;32m   3710\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39mbatch_mat_mul_v3(\n\u001b[0;32m   3711\u001b[0m       a, b, adj_x\u001b[39m=\u001b[39madjoint_a, adj_y\u001b[39m=\u001b[39madjoint_b, Tout\u001b[39m=\u001b[39moutput_type, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m   3712\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3713\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49mmat_mul(\n\u001b[0;32m   3714\u001b[0m       a, b, transpose_a\u001b[39m=\u001b[39;49mtranspose_a, transpose_b\u001b[39m=\u001b[39;49mtranspose_b, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\Littl\\anaconda3\\envs\\mlcube\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6012\u001b[0m, in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   6010\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   6011\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 6012\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   6013\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mMatMul\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, a, b, \u001b[39m\"\u001b[39;49m\u001b[39mtranspose_a\u001b[39;49m\u001b[39m\"\u001b[39;49m, transpose_a, \u001b[39m\"\u001b[39;49m\u001b[39mtranspose_b\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   6014\u001b[0m       transpose_b)\n\u001b[0;32m   6015\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   6016\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_sample_size = 1_000\n",
    "batch_size = batch_sample_size * 5\n",
    "batch_count = 1_000\n",
    "target_update_interval = 5\n",
    "\n",
    "random = Random()\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-2, decay_steps=batch_count, decay_rate=0.9\n",
    "    )\n",
    "\n",
    "network = random_network([10,15])\n",
    "\n",
    "if os.path.exists('./network.json'):\n",
    "    network = restore_network(load_json('./network.json'))\n",
    "\n",
    "save_json('./network.json',store_network(network))\n",
    "\n",
    "# Learning rate is a number between 0 and 1. It will be updated based on how accurate the network currently is. \n",
    "# For example, if the network accuracy is close to -1, then it will have a high learning rate in the next iteration, and vice versa\n",
    "learning_rate = 0.01\n",
    "\n",
    "for i in range(batch_count):\n",
    "    if i % target_update_interval == 0:\n",
    "        target = copy_network(network)\n",
    "    replay = create_replay(network, batch_size, epsilon=i / batch_count)\n",
    "    replay_sample = random.sample(replay, batch_sample_size)\n",
    "    DQN(network, target, replay_sample,lr_schedule=learning_rate)\n",
    "    value = accuracy(network)\n",
    "\n",
    "    # Update learning rate\n",
    "    learning_rate = ((-1.0 * (value - 1) / 2) ** 2) / 100\n",
    "\n",
    "    save_json('./network.json',store_network(network))\n",
    "    print(f\"Batch {i}: Accuracy: {value}, updating learning rate {learning_rate}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('mlcube')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7641580b910c9b01375a0fd9701e80f509c3f72b49a4ffa822590e7a07fce613"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
